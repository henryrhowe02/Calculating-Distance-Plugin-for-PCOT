import numpy as np
import cv2 as cv
import glob
import os
import math

type_data = np.float64

# from Camera_Calibration.Tutorial.opencv_calibrate_camera_function import calibrate_camera

# Load the images
imgL_path = r'AUPE Images/distance/pctset-1m-8bit/distance_pctset-1m-8bit_LWAC01_T00_P00_BS.png'
imgR_path = r'AUPE Images/distance/pctset-1m-8bit/distance_pctset-1m-8bit_RWAC01_T00_P00_BS.png'

# Check if the files exist
if not os.path.exists(imgL_path) or not os.path.exists(imgR_path):
    print("One or both image files not found. Please check the file paths.")
    exit()

imgL = cv.imread(imgL_path, 0)
imgR = cv.imread(imgR_path, 0)

if imgL is None or imgR is None:
    print("One or both images could not be loaded. Please check the file paths and file integrity.")
    exit()
    
# Camera parameters

left_matrix = np.array([
    [1.93479347e+03, 0.00000000e+00, 4.94465690e+02], 
    [0.00000000e+00, 1.92439346e+03, 4.16565813e+02], 
    [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]
    ], dtype=type_data)

left_dist = np.array([
    [-4.92069166e-02, -8.97949590e-01, -1.33405070e-02, -4.44237271e-03, 2.39096813e+01]
    ], dtype=type_data)

f_x_left = left_matrix[0][0]
f_y_left = left_matrix[1][1]
c_x_left = left_matrix[0][2]
c_y_left = left_matrix[1][2]

right_matrix = np.array([
    [1.93490723e+03, 0.00000000e+00, 5.26855083e+02],
    [0.00000000e+00, 1.92810886e+03, 5.05013225e+02],
    [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]
 ], dtype=type_data)

right_dist = np.array([
    [-1.49167371e-01, 1.24309868e+00, -4.14581848e-04, -3.06654869e-03, -7.74292242e+00]
    ], dtype=type_data)

f_x_right = right_matrix[0][0]
f_y_right = right_matrix[1][1]
c_x_right = right_matrix[0][2]
c_y_right = right_matrix[1][2]

focal_length_mm = 12
sensor_width_mm = 8.8
image_width_pixels = 1024
img_size = (1024, 1024)

camera_rotation = 2.8 # Inwards rotation of the cameras in degrees
total_camera_rotation = camera_rotation * 2
tcr_radians = np.deg2rad(total_camera_rotation)

# R = np.array([ # X
#     [1, 0, 0],
#     [0, np.cos(tcr_radians), -np.sin(tcr_radians)],
#     [0, np.sin(tcr_radians), np.cos(tcr_radians)]
# ], dtype=type_data)

R = np.array([ # Y
    [np.cos(tcr_radians), 0, np.sin(tcr_radians)],
    [0, 1, 0],
    [-np.sin(tcr_radians), 0, np.cos(tcr_radians)]
], dtype=type_data)

# R = np.array([ # Z
#     [np.cos(tcr_radians), -np.sin(tcr_radians), 0],
#     [np.sin(tcr_radians), np.cos(tcr_radians), 0],
#     [0, 0, 1]
# ], dtype=type_data)


baseline = 500 # Millimeters
# baseline = 0.5 # Meters
# baseline = 1 # As units instead

# toe_in_angle = baseline * math.tan(tcr_radians)

# T = np.array([
#     [baseline], [0], [0]
# ], dtype=type_data)

# Adjusting relative position so that that the T value is relative to the first camera
# Imagine that the left camera is facing forwards, instead of toed in
# By straighting this out, the right camera moves forward. 
# Using trigulation, this adjustment can be made.

adjacent = baseline * np.cos(tcr_radians)
opposite = baseline * np.sin(tcr_radians)
print("adjacent: ", adjacent)
print("opposite: ", opposite)

# T = [[Tx], [Ty], [Tz]]
# Where: Tx is horizontal displacement
#        Ty is vertical displacement
#        Tz is depth

# This should be the correct one, as openCVs coordinate system is:
# X right, Y down, Z forward
T = np.array([ # Left lower than right, left rotated sightly left
    [-adjacent], [0], [opposite]
], dtype=type_data)

# T = np.array([ # Perhaps best one? Everything rotated to the left, but looks lined up. ODD
#     [adjacent], [opposite], [0]
# ], dtype=type_data)

# T = np.array([ # Left lower than right, perhaps a slight rotation to the left for both
#     [0], [adjacent], [opposite]
# ], dtype=type_data)

# T = np.array([ # DUDD, left lower than right, both rotated to the right
#     [opposite], [adjacent], [0]
# ], dtype=type_data)

# T = np.array([ # DUDD, Black screen
#     [opposite], [0], [adjacent]
# ], dtype=type_data)

left_opt_matrix, lroi = cv.getOptimalNewCameraMatrix(left_matrix, left_dist, img_size, 1, img_size)
right_opt_matrix, rroi = cv.getOptimalNewCameraMatrix(right_matrix, right_dist, img_size, 1, img_size)

# left_opt_matrix = cv.getDefaultNewCameraMatrix(left_matrix, img_size)
# right_opt_matrix = cv.getDefaultNewCameraMatrix(right_matrix, img_size)

print("left_matrix:", left_matrix)
print("left_matrix:", left_matrix)
print("left_dist:", left_dist)
print("left_opt_matrix:", left_opt_matrix)
print("right_matrix:", right_matrix)
print("right_dist:", right_dist)
print("right_opt_matrix:", right_opt_matrix)

print("R:", R)
print("T:", T)

print("left_matrix:", left_matrix.dtype)
print("left_dist:", left_dist.dtype)
print("left optimal matrix:", left_opt_matrix.dtype)
print("right_matrix:", right_matrix.dtype)
print("right_dist:", right_dist.dtype)
print("right optimal matrix:", right_opt_matrix.dtype)
print("R:", R.dtype)
print("T:", T.dtype)

print("left_matrix shape:", left_matrix.shape)
print("left_dist shape:", left_dist.shape)
print("left_opt_matrix shape:", left_opt_matrix.shape)
print("right_matrix shape:", right_matrix.shape)
print("right_dist shape:", right_dist.shape)
print("right_opt_matrix shape:", right_opt_matrix.shape)
print("R shape:", R.shape)
print("T shape:", T.shape)

def has_nan_or_inf(matrix):
    return np.isnan(matrix).any() or np.isinf(matrix).any()

print("left_matrix has NaN or Inf:", has_nan_or_inf(left_matrix))
print("left_dist has NaN or Inf:", has_nan_or_inf(left_dist))
print("left_opt_matrix has NaN or Inf:", has_nan_or_inf(left_opt_matrix))
print("right_matrix has NaN or Inf:", has_nan_or_inf(right_matrix))
print("right_dist has NaN or Inf:", has_nan_or_inf(right_dist))
print("right_opt_matrix has NaN or Inf:", has_nan_or_inf(right_opt_matrix))
print("R has NaN or Inf:", has_nan_or_inf(R))
print("T has NaN or Inf:", has_nan_or_inf(T))

# LR, RR, p1, p2, q, roi1, roi2 = cv.stereoRectify(
#     left_matrix, left_dist, 
#     right_matrix, right_dist, 
#     img_size, 
#     R, T)

# ===================================
# USING OPTIMAL MATRIX for stereoRectify
# ===================================

LR, RR, p1, p2, q, roi1, roi2 = cv.stereoRectify(
    left_opt_matrix, left_dist, 
    right_opt_matrix, right_dist, 
    img_size, 
    R, T,
    # flags=cv.CALIB_ZERO_DISPARITY,
    )

# try:
#     LR, RR, p1, p2, q, roi1, roi2 = cv.stereoRectify(
#         left_matrix.astype(type_data), left_dist.astype(type_data), 
#         right_matrix.astype(type_data), right_dist.astype(type_data), 
#         img_size, 
#         R.astype(type_data), T.astype(type_data))
#     print("Stereo rectification successful")
# except cv.error as e:
#     print("Stereo rectification error:", e)

# ===================================
# Looking at using undistort based on info from openCV calibrate_camera_function
# ===================================

# ldst = cv.undistort(imgL, left_matrix, left_dist, None, LR)
# rdst = cv.undistort(imgR, right_matrix, right_dist, None, RR)

# lx, ly, lw, lh = roi1
# rx, ry, rw, rh = roi2

# ldst = ldst[ly:ly+lh, lx:lx+lw]
# rdst = rdst[ry:ry+rh, rx:rx+rw]

# cv.imshow("left result", ldst)
# cv.imshow("right result", rdst)
# cv.waitKey(0)
# cv.destroyAllWindows()

# ===================================
# ADJUSTING BASED ON STACK OVERFLOW ANSWER
# ===================================

# LR_fix = LR.dot(np.linalg.inv(left_matrix))
# RR_fix = RR.dot(np.linalg.inv(right_matrix))

# LR = LR_fix.copy()
# RR = RR_fix.copy()

# ===================================
# USING REGULAR MATRIX for initUndistortRectifyMap
# ===================================

left_map1, left_map2 = cv.initUndistortRectifyMap(
    left_matrix, left_dist, 
    LR, 
    # None,
    p1, img_size, cv.CV_32FC1)

right_map1, right_map2 = cv.initUndistortRectifyMap(
    right_matrix, right_dist, 
    RR, 
    # None,
    p2, img_size, cv.CV_32FC1)

# ===================================
# USING OPTIMAL MATRIX for initUndistortRectifyMap
# ===================================

# left_map1, left_map2 = cv.initUndistortRectifyMap(
#     left_opt_matrix, left_dist, 
#     # RR,
#     LR, 
#     # None,
#     p1, img_size, cv.CV_32FC1)

# right_map1, right_map2 = cv.initUndistortRectifyMap(
#     right_opt_matrix, right_dist, 
#     RR, 
#     # None,
#     p2, img_size, cv.CV_32FC1)

left_rectified = cv.remap(imgL, left_map1, left_map2, cv.INTER_LINEAR)
right_rectified = cv.remap(imgR, right_map1, right_map2, cv.INTER_LINEAR)

def draw_horizontal_lines(img, num_lines=20, color=(0, 255, 0)):
    h, w = img.shape[:2]
    interval = h // num_lines
    for i in range(0, h, interval):
        cv.line(img, (0, i), (w, i), color, 1)

imgL_rect_color = cv.cvtColor(left_rectified, cv.COLOR_GRAY2BGR)
imgR_rect_color = cv.cvtColor(right_rectified, cv.COLOR_GRAY2BGR)

# draw_horizontal_lines(imgL_rect_color)
# draw_horizontal_lines(imgR_rect_color)

combined = cv.hconcat([imgL_rect_color, imgR_rect_color])

cv.namedWindow("Rectified Images", 
cv.WINDOW_NORMAL
)
cv.imshow('Rectified Images', combined)
cv.waitKey(0)
cv.destroyAllWindows()

# combined_image = np.hstack((left_rectified, right_rectified))

# cv.namedWindow("Rectified Images", 
# cv.WINDOW_NORMAL
# )
# cv.resizeWindow("Rectified Images", 1200, 600)
# cv.imshow("Rectified Images", combined_image)
# # cv.setMouseCallback('Rectified Images', click_event_combined)
# cv.waitKey(0)
# cv.destroyAllWindows()